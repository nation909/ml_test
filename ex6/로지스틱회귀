로지스틱회귀
참, 거짓으로만 판단해야하는 경우 사용
딥러닝에서는 주로 전달받은 정보를 가지고 참, 거짓을 판단해서 다음단계로 넘기는 방식으로 사용함

EX.
공부한시간: [2, 4, 6, 8, 10, 12, 14]
합격 여부: ['불합격', '불합격', '불합격', '합격', '합격', '합격', '합격']

로지스틱회귀도 선형회귀와 마찬가지로 0(불합격), 1(합격)으로 선을그림
- S자 형태의 선으로 그려짐

시그모이드 함수
- S자 형태로 그래프가 그려지는 함수

시그모이드함수 방정식
y = 1 / (1 + e^(-ax + b))

e: 자연상수라고 불리는 무리수(값은 2.71828...)
- 수학에서 파이처럼 상수로 고정된 값으로 따로 구하는 값은 아님
a: 그래프의 경사도를 결정(a값이 크면 경사가크고, a값이 작으면 경사가 작음)
b: 그래프의 좌,우 이동을 의미(b값이 작고 큼에따라 그래프가 이동함)

실제로 구해야할 값은 a, x, b를 구하면 됌

로그함수
- 시그모이드함수의 특징은 y값이 0~1사이의 값임
- EX. 실제값이 0일경우 예측값이 1로 가면 갈수록 오차가 커지고
-  실제값이1일때 예측값이 0으로 가면 갈수록 오차가 커짐
- 이를 공식으로 만들수 있는 함수가 로그함수임

y의 실제값이 0일때 -log(1-h)를 사용
y의 실제값이 1일때 -log h를 사용

# 오차 = -평균(y * log h + (1 - y) * log(1 - h))
               ----A-----  ----------B---------
A: 실제값이 0일때
B: 실제값이 1일때

h: 시그모이드함수에서나온 y값 인듯?
