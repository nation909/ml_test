# 순환신경망(RNN)
1번째에 입력된 데이터와 2번째에 입력된 데이터 사이의 관계가 상관이 없었지만
문장을 듣고 이해한다는 것은 입력된 데이터들의 사이의 관계를 고려해야 하는 문제가 있음
이를 해결하기위해 순환신경망(RNN)방법이 고안됨

순환신경망은 여러개의 데이터가 순서대로 입력되었을때 앞서 입력받은 데이터를 잠시 기억해 놓는 방법
그리고 기억된 데이터가 얼마나 중요한지를 판단하여 별도의 가중치를 줘서 다음 데이터로 넘어감
모든입력값에 이작업을 순서대로 실행하므로 다음층으로 넘어가기 전에 같은층을 맴도는 성질때문에 순환신경망이라고 부름

EX. 오늘 주가가 몇이야? 라고 입력이 들어왔을때
입력1: '오늘' -> '오늘'에 대한 결과 -> 기억1 ->
-> 입력2: '주가가' -> '주가가'에 대한 결과 -> 기억2
-> 입력3: '몇이야' -> '몇이야'에 대한 결과 -> 출력

# LSTM(Long Short Term Memory)
RNN이 처음 개발된 이후, 결과를 더욱 개선하기 위한 노력이 계속 되었는데
이 중 LSTM(Long Short Term Memory)방법을 함께 사용하는 기법이 가장 널리 사용됨
LSTM은 한 층 안에서 반복을 많이 해야 하는
RNN특성상 기울기 소실문제가 많이 발생하고 이를 해결하기 어렵다는 단점을 보완함
즉, 반복되기 직전에 다음 층으로 기억된 값을 넘길지 안넘길지를 관리하는 단계를 하나더 추가하는 것임

# RNN 방식의 종류
1. 다수 입력 단일 출력(EX. 밥은 먹고 다니니?. 문장을 읽고 뜻을 파악할때 활용)
밥은 -> 먹고 -> 다니니? -> 안부인사

2. 단일 입력 다수 출력(EX. 강아지가 이불덮고 있는사진. 사진의 캡션을 만들때 활용)
강아지 -> 이불 -> 요다?

3. 다수 입력 다수 출력(EX. 예 그게 다예요. 문장을 번역할때 사용)
예 -> 그게 -> 다예요 -> yes -> that`s -> all

# LSTM을 이용한 로이터뉴스 카테고리 분류하기
입력된 문장의 의미를 파악하는 것은, 모든 단어를 종합하여 하나의 카테고리로 분류하는 작업임
EX.
'안녕 오늘 날씨가 참 좋네' -> '인사'카테고리에 분류해야 함
'중부 지방은 대체로 맑겠으나, 남부 지방은 구름이 많겠습니다' -> '날씨' 카테고리
'올 초부터 유동성의 힘으로 주가가 일정하게 상승했습니다.' -> '주식' 카테고리
'이번 선거에서는 누가 이길 것 같아?' -> 정치
'퍼셉트론의 한계를 극복한 신경망이 다시 뜨고 있대' -> 딥러닝

로이터뉴스 11,258개의 뉴스기사가 46개의 카테고리로 분류되어 있는 대용량 텍스트 데이터 활용
